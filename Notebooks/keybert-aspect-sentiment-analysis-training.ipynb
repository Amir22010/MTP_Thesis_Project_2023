{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://github.com/kevinscaria/InstructABSA/","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install keybert #keybert\n!pip install datasets\n!pip install evaluate\n!pip install sentencepiece\n!pip install -U accelerate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Restart","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/kevinscaria/InstructABSA.git","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import pandas as pd\n#df_train_i = pd.read_json('/kaggle/input/annotationspyabsa/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result_English_Train.json',orient='records')\n#df_train_i.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_train_i.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_valid_i = pd.read_json('/kaggle/input/annotationspyabsa/Aspect Term Extraction and Polarity Classification.FAST_LCF_ATEPC.result_English_Valid.json',orient='records')\n#df_valid_i.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_valid_i.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## KeyBert + Sentiment","metadata":{}},{"cell_type":"code","source":"'''\nfrom keybert import KeyBERT\nkw_model = KeyBERT()\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import pipeline\nmodel_name = \"yangheng/deberta-v3-base-absa-v1.1\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\nclassifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfinal_train_data = []\nfor row in df_train_i.itertuples():\n    polarity = []\n    combine = []\n    try:\n        keywords = kw_model.extract_keywords(row.sentence)\n        combine +=[i[0] for i in keywords]\n        for aspect in [i[0] for i in keywords]:\n            polarity += [classifier(row.sentence,  text_pair=aspect)[0]['label']]\n        final_train_data.append([row.sentence,combine,polarity])\n    except:\n        print(row.sentence)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nfinal_valid_data = []\nfor row in df_valid_i.itertuples():\n    polarity = []\n    combine = []\n    try:\n        keywords = kw_model.extract_keywords(row.sentence)\n        combine +=[i[0] for i in keywords]\n        for aspect in [i[0] for i in keywords]:\n            polarity += [classifier(row.sentence,  text_pair=aspect)[0]['label']]\n        final_valid_data.append([row.sentence,combine,polarity])\n    except:\n        print(row.sentence)\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#key_train = pd.DataFrame(final_train_data, columns =['sentence', 'aspect','polarity'])\n#key_valid = pd.DataFrame(final_valid_data, columns =['sentence', 'aspect','polarity'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#key_train.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#key_valid.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#key_train.to_csv('key_train.csv',index=False)\n#key_valid.to_csv('key_valid.csv',index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf_train_i = pd.read_csv('/kaggle/input/kerybertaspect/key_train.csv')\ndf_valid_i = pd.read_csv('/kaggle/input/kerybertaspect/key_valid.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:52:22.875190Z","iopub.execute_input":"2023-07-25T04:52:22.875596Z","iopub.status.idle":"2023-07-25T04:52:22.961072Z","shell.execute_reply.started":"2023-07-25T04:52:22.875563Z","shell.execute_reply":"2023-07-25T04:52:22.960066Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## create a model with generate aspect with sentiment using same model","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nuse_mps = True if torch.has_mps else False\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nfrom InstructABSA.InstructABSA.data_prep import DatasetLoader","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:52:26.170601Z","iopub.execute_input":"2023-07-25T04:52:26.170967Z","iopub.status.idle":"2023-07-25T04:52:28.321228Z","shell.execute_reply.started":"2023-07-25T04:52:26.170936Z","shell.execute_reply":"2023-07-25T04:52:28.320234Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class InstructionsHandler:\n    def __init__(self):\n        self.joint = {}\n    def load_instruction_set(self, ):\n        self.joint['bos_instruct'] = \"\"\"Definition: The output will be the aspects (both implicit and explicit) and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspectterm:none.\n        Positive example 1-\n        input: this hospital has a good team of doctors who will take care of all your needs brilliantly.\n        output: doctors:positive\n        Positive example 2- \n        input: Arthur as Irv at ham hospital ran an Nagar , Madurai has a doctor who engages you in a conversation and tries to take your mind off the pain and he has trained the staff to do so as well.\n        output: doctor:positive, staff:positive\n        Now complete the following example-\n        input: \"\"\"\n        self.joint['delim_instruct'] = ''\n        self.joint['eos_instruct'] = ' \\noutput:'","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:52:29.747919Z","iopub.execute_input":"2023-07-25T04:52:29.749142Z","iopub.status.idle":"2023-07-25T04:52:29.755933Z","shell.execute_reply.started":"2023-07-25T04:52:29.749099Z","shell.execute_reply":"2023-07-25T04:52:29.754963Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\ntask_name = 'joint_task'\nexperiment_name = 'custom_absa'\nmodel_checkpoint = 'allenai/tk-instruct-base-def-pos' #base model\n#model_checkpoint = 'kevinscaria/joint_tk-instruct-base-def-pos-neg-neut-combined' #pre-trained model\nprint('Experiment Name: ', experiment_name)\nmodel_out_path = './Models'\nmodel_out_path = os.path.join(model_out_path, task_name, f\"{model_checkpoint.replace('/', '')}-{experiment_name}\")\nprint('Model output path: ', model_out_path)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:50:23.272209Z","iopub.execute_input":"2023-07-25T04:50:23.273088Z","iopub.status.idle":"2023-07-25T04:50:23.281353Z","shell.execute_reply.started":"2023-07-25T04:50:23.273051Z","shell.execute_reply":"2023-07-25T04:50:23.280040Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Experiment Name:  custom_absa\nModel output path:  ./Models/joint_task/allenaitk-instruct-base-def-pos-custom_absa\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train_i = df_train_i.rename(columns={'polarity': 'sentiment'})\ndf_valid_i = df_valid_i.rename(columns={'polarity': 'sentiment'})","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:00.644007Z","iopub.execute_input":"2023-07-25T04:54:00.644659Z","iopub.status.idle":"2023-07-25T04:54:00.652308Z","shell.execute_reply.started":"2023-07-25T04:54:00.644618Z","shell.execute_reply":"2023-07-25T04:54:00.651237Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import ast\ndf_train = df_train_i[['sentence','aspect','sentiment']]\ndf_train.rename(columns={'sentence': 'raw_text'}, inplace=True)\ndf_train['aspectTerms'] = ''\nfor i in df_train.itertuples():\n    try:\n        if len(i.aspect) > 0:\n            k = [{'term': j[0],'polarity':j[1]} for j in list(zip(ast.literal_eval(i.aspect),ast.literal_eval(i.sentiment)))]\n        else:\n            k = [{'term':'noaspectterm', 'polarity':'none'}]\n        df_train.at[i.Index, 'aspectTerms'] = k\n    except Exception as e:\n        print(e)\ndf_train = df_train[['raw_text','aspectTerms']]\ndf_train.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:06.289557Z","iopub.execute_input":"2023-07-25T04:54:06.289925Z","iopub.status.idle":"2023-07-25T04:54:07.323724Z","shell.execute_reply.started":"2023-07-25T04:54:06.289895Z","shell.execute_reply":"2023-07-25T04:54:07.322027Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                            raw_text  \\\n0  everyone in this hospital from the staff to th...   \n\n                                         aspectTerms  \n0  [{'term': 'patients', 'polarity': 'Positive'},...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_text</th>\n      <th>aspectTerms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>everyone in this hospital from the staff to th...</td>\n      <td>[{'term': 'patients', 'polarity': 'Positive'},...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_valid = df_valid_i[['sentence','aspect','sentiment']]\ndf_valid.rename(columns={'sentence': 'raw_text'}, inplace=True)\ndf_valid['aspectTerms'] = ''\nfor i in df_valid.itertuples():\n    try:\n        if len(i.aspect) > 0:\n            k = [{'term': j[0],'polarity':j[1]} for j in list(zip(ast.literal_eval(i.aspect),ast.literal_eval(i.sentiment)))]\n        else:\n            k = [{'term':'noaspectterm', 'polarity':'none'}]\n        df_valid.at[i.Index, 'aspectTerms'] = k\n    except Exception as e:\n        print(e)\ndf_valid = df_valid[['raw_text','aspectTerms']]\ndf_valid.head(1)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:22.583585Z","iopub.execute_input":"2023-07-25T04:54:22.584059Z","iopub.status.idle":"2023-07-25T04:54:22.860612Z","shell.execute_reply.started":"2023-07-25T04:54:22.584025Z","shell.execute_reply":"2023-07-25T04:54:22.859526Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                            raw_text  \\\n0  the staff the nurses and the doctors are highl...   \n\n                                         aspectTerms  \n0  [{'term': 'gora', 'polarity': 'Positive'}, {'t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_text</th>\n      <th>aspectTerms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the staff the nurses and the doctors are highl...</td>\n      <td>[{'term': 'gora', 'polarity': 'Positive'}, {'t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_valid.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:27.272473Z","iopub.execute_input":"2023-07-25T04:54:27.272862Z","iopub.status.idle":"2023-07-25T04:54:27.279209Z","shell.execute_reply.started":"2023-07-25T04:54:27.272831Z","shell.execute_reply":"2023-07-25T04:54:27.278252Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(4239, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df_valid.tail(2)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:29.914034Z","iopub.execute_input":"2023-07-25T04:54:29.915183Z","iopub.status.idle":"2023-07-25T04:54:29.930520Z","shell.execute_reply.started":"2023-07-25T04:54:29.915134Z","shell.execute_reply":"2023-07-25T04:54:29.929339Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                               raw_text  \\\n4237  the doctors at this hospital have at least yea...   \n4238  I underwent a very complicated surgery at ran ...   \n\n                                            aspectTerms  \n4237  [{'term': 'surgery', 'polarity': 'Neutral'}, {...  \n4238  [{'term': 'surgery', 'polarity': 'Negative'}, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_text</th>\n      <th>aspectTerms</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4237</th>\n      <td>the doctors at this hospital have at least yea...</td>\n      <td>[{'term': 'surgery', 'polarity': 'Neutral'}, {...</td>\n    </tr>\n    <tr>\n      <th>4238</th>\n      <td>I underwent a very complicated surgery at ran ...</td>\n      <td>[{'term': 'surgery', 'polarity': 'Negative'}, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#testing dataset\ndf_test = df_valid[0:1000]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:31.966267Z","iopub.execute_input":"2023-07-25T04:54:31.966651Z","iopub.status.idle":"2023-07-25T04:54:31.972389Z","shell.execute_reply.started":"2023-07-25T04:54:31.966619Z","shell.execute_reply":"2023-07-25T04:54:31.970505Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:36.289594Z","iopub.execute_input":"2023-07-25T04:54:36.290378Z","iopub.status.idle":"2023-07-25T04:54:36.296881Z","shell.execute_reply.started":"2023-07-25T04:54:36.290338Z","shell.execute_reply":"2023-07-25T04:54:36.295813Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(1000, 2)"},"metadata":{}}]},{"cell_type":"code","source":"df_valid = df_valid[1000:]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:38.729777Z","iopub.execute_input":"2023-07-25T04:54:38.730175Z","iopub.status.idle":"2023-07-25T04:54:38.735194Z","shell.execute_reply.started":"2023-07-25T04:54:38.730141Z","shell.execute_reply":"2023-07-25T04:54:38.734189Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_valid.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:40.634414Z","iopub.execute_input":"2023-07-25T04:54:40.635540Z","iopub.status.idle":"2023-07-25T04:54:40.643438Z","shell.execute_reply.started":"2023-07-25T04:54:40.635498Z","shell.execute_reply":"2023-07-25T04:54:40.642134Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(3239, 2)"},"metadata":{}}]},{"cell_type":"code","source":"# Get the input text into the required format using Instructions\ninstruct_handler = InstructionsHandler()\n\n# Set instruction_set1 for InstructABSA-1 and instruction_set2 for InstructABSA-2\ninstruct_handler.load_instruction_set()\n\n# Set bos_instruct1 for lapt14 and bos_instruct2 for rest14. For other datasets, modify the insructions.py file.\nloader = DatasetLoader(df_train, df_test, df_valid)\nif loader.train_df_id is not None:\n    loader.train_df_id = loader.create_data_in_aspe_format(loader.train_df_id, 'term', 'polarity', 'raw_text', 'aspectTerms', instruct_handler.joint['bos_instruct'], instruct_handler.joint['eos_instruct'])\nif loader.test_df_id is not None:\n    loader.test_df_id = loader.create_data_in_aspe_format(loader.test_df_id, 'term', 'polarity', 'raw_text', 'aspectTerms', instruct_handler.joint['bos_instruct'], instruct_handler.joint['eos_instruct'])\nif loader.val_df_id is not None:\n    loader.val_df_id = loader.create_data_in_aspe_format(loader.val_df_id, 'term', 'polarity', 'raw_text', 'aspectTerms', instruct_handler.joint['bos_instruct'], instruct_handler.joint['eos_instruct'])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:54:43.130742Z","iopub.execute_input":"2023-07-25T04:54:43.131874Z","iopub.status.idle":"2023-07-25T04:54:43.238975Z","shell.execute_reply.started":"2023-07-25T04:54:43.131833Z","shell.execute_reply":"2023-07-25T04:54:43.237916Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport sys\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm import tqdm\nfrom transformers import (\n    DataCollatorForSeq2Seq, AutoTokenizer, AutoModelForSeq2SeqLM,\n    Seq2SeqTrainingArguments, Trainer, Seq2SeqTrainer\n)\n\n\nclass T5Generator:\n    def __init__(self, model_checkpoint):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer)\n        self.device = 'cuda' if torch.has_cuda else ('mps' if torch.has_mps else 'cpu')\n\n    def tokenize_function_inputs(self, sample):\n        \"\"\"\n        Udf to tokenize the input dataset.\n        \"\"\"\n        model_inputs = self.tokenizer(sample['text'], max_length=512, truncation=True)\n        labels = self.tokenizer(sample[\"labels\"], max_length=64, truncation=True)\n        model_inputs[\"labels\"] = labels[\"input_ids\"]\n        return model_inputs\n        \n    def train(self, tokenized_datasets, **kwargs):\n        \"\"\"\n        Train the generative model.\n        \"\"\"\n        #Set training arguments\n        args = Seq2SeqTrainingArguments(\n            **kwargs\n        )\n\n        # Define trainer object\n        trainer = Seq2SeqTrainer(\n            self.model,\n            args,\n            train_dataset=tokenized_datasets[\"train\"],\n            eval_dataset=tokenized_datasets[\"validation\"] if tokenized_datasets.get(\"validation\") is not None else None,\n            tokenizer=self.tokenizer,\n            data_collator=self.data_collator,\n        )\n        print(\"Trainer device:\", trainer.args.device)\n\n        # Finetune the model\n        torch.cuda.empty_cache()\n        print('\\nModel training started ....')\n        trainer.train()\n\n        # Save best model\n        trainer.save_model()\n        return trainer\n\n    def get_labels(self, tokenized_dataset, batch_size = 4, max_length = 512, sample_set = 'train'):\n        \"\"\"\n        Get the predictions from the trained model.\n        \"\"\"\n        def collate_fn(batch):\n            input_ids = [torch.tensor(example['input_ids']) for example in batch]\n            input_ids = pad_sequence(input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id)\n            return input_ids\n        dataloader = DataLoader(tokenized_dataset[sample_set], batch_size=batch_size, collate_fn=collate_fn)\n        predicted_output = []\n        predict_probability = []\n        self.model.to(self.device)\n        print('Model loaded to: ', self.device)\n\n        for batch in tqdm(dataloader):\n            batch = batch.to(self.device)\n            output_ids = self.model.generate(batch, max_length = max_length)\n            output_ids_prob = self.model.generate(batch,return_dict_in_generate=True, output_scores=True,top_p=.9, max_length=max_length)\n            transition_scores = self.model.compute_transition_scores(output_ids_prob.sequences, output_ids_prob.scores, normalize_logits=True)\n            predict_probability += [np.exp(transition_scores.cpu().numpy())[i].sum(axis=0)/len(transition_scores[i]) for i in range(len(transition_scores))]\n            output_texts = self.tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n            for output_text in output_texts:\n                predicted_output.append(output_text)\n        return predicted_output, predict_probability\n    \n    def get_metrics(self, y_true, y_pred, is_triplet_extraction=False):\n\n        total_pred = 0\n        total_gt = 0\n        tp = 0\n\n        if not is_triplet_extraction:\n            for gt, pred in zip(y_true, y_pred):\n                gt_list = gt.split(', ')\n                pred_list = pred.split(', ')\n                total_pred+=len(pred_list)\n                total_gt+=len(gt_list)\n                for gt_val in gt_list:\n                    for pred_val in pred_list:\n                        if pred_val in gt_val or gt_val in pred_val:\n                            tp+=1\n                            break\n\n        else:\n            for gt, pred in zip(y_true, y_pred):\n                gt_list = gt.split(', ')\n                pred_list = pred.split(', ')\n                total_pred+=len(pred_list)\n                total_gt+=len(gt_list)\n                for gt_val in gt_list:\n                    gt_asp = gt_val.split(':')[0]\n\n                    try:\n                        gt_op = gt_val.split(':')[1]\n                    except:\n                        continue\n\n                    try:\n                        gt_sent = gt_val.split(':')[2]\n                    except:\n                        continue\n\n                    for pred_val in pred_list:\n                        pr_asp = pred_val.split(':')[0]\n\n                        try:\n                            pr_op = pred_val.split(':')[1]\n                        except:\n                            continue\n\n                        try:\n                            pr_sent = gt_val.split(':')[2]\n                        except:\n                            continue\n\n                        if pr_asp in gt_asp and pr_op in gt_op and gt_sent == pr_sent:\n                            # print(gt_asp, pr_asp, ' --> ', gt_op, pr_op, ' --> ', gt_sent, pr_sent)\n                            tp+=1\n\n        p = tp/total_pred\n        r = tp/total_gt\n        return p, r, 2*p*r/(p+r), None","metadata":{"execution":{"iopub.status.busy":"2023-07-25T07:36:58.377123Z","iopub.execute_input":"2023-07-25T07:36:58.377539Z","iopub.status.idle":"2023-07-25T07:36:58.407462Z","shell.execute_reply.started":"2023-07-25T07:36:58.377508Z","shell.execute_reply":"2023-07-25T07:36:58.406327Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Create T5 utils object\nt5_exp = T5Generator(model_checkpoint)\n# Tokenize Dataset\nid_ds, id_tokenized_ds, ood_ds, ood_tokenized_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:56:05.025529Z","iopub.execute_input":"2023-07-25T04:56:05.025912Z","iopub.status.idle":"2023-07-25T04:56:56.884152Z","shell.execute_reply.started":"2023-07-25T04:56:05.025880Z","shell.execute_reply":"2023-07-25T04:56:56.883047Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/2.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eee1ac63ac849448b188e4b84afbb7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f249c8a4d5c443668c508b1564dec1f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"465a3765299e4b83ab3825ade5ab95b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ed727a85de44203b829926260099d9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e155b0fdeb0472481f097b87bcc21b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/495M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7efd593b4cf9493fac930416c27c1087"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47f71f06cdae4b509a696f0809b421a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9b548aafe8c40429972f316aadc8d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22f574ab18bf4d94bab32ecdb356704e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c68b23e05a694fdcaf52c4a872b55af6"}},"metadata":{}}]},{"cell_type":"code","source":"id_ds","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:56:59.751724Z","iopub.execute_input":"2023-07-25T04:56:59.752127Z","iopub.status.idle":"2023-07-25T04:56:59.758344Z","shell.execute_reply.started":"2023-07-25T04:56:59.752088Z","shell.execute_reply":"2023-07-25T04:56:59.757411Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['raw_text', 'aspectTerms', 'labels', 'text', '__index_level_0__'],\n        num_rows: 16956\n    })\n    test: Dataset({\n        features: ['raw_text', 'aspectTerms', 'labels', 'text'],\n        num_rows: 1000\n    })\n    validation: Dataset({\n        features: ['raw_text', 'aspectTerms', 'labels', 'text'],\n        num_rows: 3239\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"id_tokenized_ds","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:57:02.706593Z","iopub.execute_input":"2023-07-25T04:57:02.707056Z","iopub.status.idle":"2023-07-25T04:57:02.714108Z","shell.execute_reply.started":"2023-07-25T04:57:02.707020Z","shell.execute_reply":"2023-07-25T04:57:02.712965Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['raw_text', 'aspectTerms', 'labels', 'text', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 16956\n    })\n    test: Dataset({\n        features: ['raw_text', 'aspectTerms', 'labels', 'text', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n    validation: Dataset({\n        features: ['raw_text', 'aspectTerms', 'labels', 'text', 'input_ids', 'attention_mask'],\n        num_rows: 3239\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Training arguments\ntraining_args = {\n    'output_dir':model_out_path,\n    'evaluation_strategy':\"epoch\",\n    'learning_rate':5e-5,\n    'lr_scheduler_type':'cosine',\n    'per_device_train_batch_size':4,\n    'per_device_eval_batch_size':4,\n    'num_train_epochs':8,\n    'weight_decay':0.01,\n    'warmup_ratio':0.1,\n    'save_strategy':'no',\n    'load_best_model_at_end':False,\n    'push_to_hub':False,\n    'eval_accumulation_steps':1,\n    'predict_with_generate':True,\n    'use_mps_device':use_mps,\n    'fp16_full_eval':True\n}","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:57:05.251825Z","iopub.execute_input":"2023-07-25T04:57:05.252920Z","iopub.status.idle":"2023-07-25T04:57:05.259766Z","shell.execute_reply.started":"2023-07-25T04:57:05.252881Z","shell.execute_reply":"2023-07-25T04:57:05.258776Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Train model\nmodel_trainer = t5_exp.train(id_tokenized_ds, **training_args)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T04:57:11.877902Z","iopub.execute_input":"2023-07-25T04:57:11.878324Z","iopub.status.idle":"2023-07-25T06:49:54.394415Z","shell.execute_reply.started":"2023-07-25T04:57:11.878290Z","shell.execute_reply":"2023-07-25T06:49:54.393045Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Trainer device: cuda:0\n\nModel training started ....\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230725_045735-4505ajhj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/amir22010/huggingface/runs/4505ajhj' target=\"_blank\">golden-feather-21</a></strong> to <a href='https://wandb.ai/amir22010/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/amir22010/huggingface' target=\"_blank\">https://wandb.ai/amir22010/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/amir22010/huggingface/runs/4505ajhj' target=\"_blank\">https://wandb.ai/amir22010/huggingface/runs/4505ajhj</a>"},"metadata":{}},{"name":"stderr","text":"You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='33912' max='33912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [33912/33912 1:51:44, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.150800</td>\n      <td>0.112104</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.103700</td>\n      <td>0.074400</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.074500</td>\n      <td>0.065034</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.065900</td>\n      <td>0.062676</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.059700</td>\n      <td>0.058017</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.050700</td>\n      <td>0.056635</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.046500</td>\n      <td>0.056589</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.046300</td>\n      <td>0.056924</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# Model inference - Loading from Checkpoint\nt5_exp = T5Generator(model_out_path)\n\n# Tokenize Datasets\nid_ds, id_tokenized_ds, ood_ds, ood_tokenzed_ds = loader.set_data_for_training_semeval(t5_exp.tokenize_function_inputs)\n\n# Get prediction labels - Training set   \nid_tr_pred_labels, id_tr_pred_prob = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'train', batch_size = 16)\nid_tr_labels = [i.strip() for i in id_ds['train']['labels']]\n\n# Get prediction labels - Validation set\nid_te_pred_labels, id_te_pred_prob = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'validation', batch_size = 16)\nid_te_labels = [i.strip() for i in id_ds['validation']['labels']]\n\n# Get prediction labels - UnseenTest set\nid_test_pred_labels, id_test_pred_prob = t5_exp.get_labels(tokenized_dataset = id_tokenized_ds, sample_set = 'test', batch_size = 16)\nid_test_labels = [i.strip() for i in id_ds['test']['labels']]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T07:42:15.449147Z","iopub.execute_input":"2023-07-25T07:42:15.450331Z","iopub.status.idle":"2023-07-25T08:21:04.407430Z","shell.execute_reply.started":"2023-07-25T07:42:15.450286Z","shell.execute_reply":"2023-07-25T08:21:04.406025Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"276d0584e18545bba993a401970ab35c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172a807f15734860b6b2fff2278aae87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a31435977cc4036bd6004cf72c06d9a"}},"metadata":{}},{"name":"stdout","text":"Model loaded to:  cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1060/1060 [30:50<00:00,  1.75s/it]\n","output_type":"stream"},{"name":"stdout","text":"Model loaded to:  cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 203/203 [05:53<00:00,  1.74s/it]\n","output_type":"stream"},{"name":"stdout","text":"Model loaded to:  cuda\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 63/63 [01:50<00:00,  1.75s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"len(id_tr_pred_prob)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_tr_pred_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_tr_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('actual_train_labels.txt','w',encoding='utf-8') as f:\n    f.write(str(id_tr_labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_tr_pred_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_te_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('actual_test_labels.txt','w',encoding='utf-8') as f:\n    f.write(str(id_te_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_te_pred_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('predicted_test_labels.txt','w',encoding='utf-8') as f:\n    f.write(str(id_te_pred_labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p, r, f1, _ = t5_exp.get_metrics(id_tr_labels, id_tr_pred_labels)\nprint('Train Precision: ', p)\nprint('Train Recall: ', r)\nprint('Train F1: ', f1)\np, r, f1, _ = t5_exp.get_metrics(id_te_labels, id_te_pred_labels)\nprint('Test Precision: ', p)\nprint('Test Recall: ', r)\nprint('Test F1: ', f1)\np, r, f1, _ = t5_exp.get_metrics(id_test_labels, id_test_pred_labels)\nprint('UnseenTest Precision: ', p)\nprint('UnseenTest Recall: ', r)\nprint('UnseenTest F1: ', f1)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T08:32:04.627893Z","iopub.execute_input":"2023-07-25T08:32:04.628400Z","iopub.status.idle":"2023-07-25T08:32:04.738932Z","shell.execute_reply.started":"2023-07-25T08:32:04.628364Z","shell.execute_reply":"2023-07-25T08:32:04.737875Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Train Precision:  0.9552227554840818\nTrain Recall:  0.9552107544443746\nTrain F1:  0.9552167549265339\nTest Precision:  0.9300919842312746\nTest Recall:  0.9301530981010578\nTest F1:  0.9301225401622918\nUnseenTest Precision:  0.9329632792485055\nUnseenTest Recall:  0.9329632792485055\nUnseenTest F1:  0.9329632792485054\n","output_type":"stream"}]},{"cell_type":"code","source":"id_tr_pred_labels[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_tr_labels[0].split(',')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check = pd.DataFrame(id_ds['train']['raw_text'], columns=['clean_text'])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T08:32:25.065891Z","iopub.execute_input":"2023-07-25T08:32:25.066935Z","iopub.status.idle":"2023-07-25T08:32:25.105722Z","shell.execute_reply.started":"2023-07-25T08:32:25.066898Z","shell.execute_reply":"2023-07-25T08:32:25.104525Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"check['actual_label'] = id_tr_labels\ncheck['actual_aspects'] = [str([i.split(':')[0] for i in id_tr_labels[j].split(',')]) for j in range(len(id_tr_labels))]\ncheck['actual_sentiments'] = [str([i.split(':')[1] for i in id_tr_labels[j].split(',')]) for j in range(len(id_tr_labels))]\ncheck['model_text_generated_label'] = id_tr_pred_labels\ncheck['predicted_aspects'] = [str([i.split(':')[0] for i in id_tr_pred_labels[j].split(',')]) for j in range(len(id_tr_pred_labels))]\ncheck['predicted_sentiments'] = [str([i.split(':')[1] for i in id_tr_pred_labels[j].split(',')]) for j in range(len(id_tr_pred_labels))]\ncheck['model_text_generate_probability']=id_tr_pred_prob","metadata":{"execution":{"iopub.status.busy":"2023-07-25T08:32:26.911963Z","iopub.execute_input":"2023-07-25T08:32:26.912688Z","iopub.status.idle":"2023-07-25T08:32:27.164653Z","shell.execute_reply.started":"2023-07-25T08:32:26.912652Z","shell.execute_reply":"2023-07-25T08:32:27.163340Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"check['dataset_type'] = ['train']*check.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T08:32:29.864255Z","iopub.execute_input":"2023-07-25T08:32:29.864636Z","iopub.status.idle":"2023-07-25T08:32:29.873554Z","shell.execute_reply.started":"2023-07-25T08:32:29.864603Z","shell.execute_reply":"2023-07-25T08:32:29.872405Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"check.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_polarity = []\nfor j in range(len(id_te_labels)):\n    try:\n        valid_polarity+=[str([i.split(':')[1] for i in id_te_labels[j].split(',')])]\n    except:\n        valid_polarity+=[\"\"]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:04:55.598431Z","iopub.execute_input":"2023-07-25T09:04:55.599252Z","iopub.status.idle":"2023-07-25T09:04:55.624723Z","shell.execute_reply.started":"2023-07-25T09:04:55.599208Z","shell.execute_reply":"2023-07-25T09:04:55.621892Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"len(valid_polarity)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:05:03.787182Z","iopub.execute_input":"2023-07-25T09:05:03.787744Z","iopub.status.idle":"2023-07-25T09:05:03.797361Z","shell.execute_reply.started":"2023-07-25T09:05:03.787713Z","shell.execute_reply":"2023-07-25T09:05:03.796167Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"3239"},"metadata":{}}]},{"cell_type":"code","source":"[str([i.split(':')[1] if for i in id_te_labels[j].split(',')]) for j in range(len(id_te_labels))]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T08:59:17.085271Z","iopub.execute_input":"2023-07-25T08:59:17.085668Z","iopub.status.idle":"2023-07-25T08:59:17.218128Z","shell.execute_reply.started":"2023-07-25T08:59:17.085635Z","shell.execute_reply":"2023-07-25T08:59:17.216756Z"},"trusted":true},"execution_count":51,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[38;5;28mstr\u001b[39m([i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m id_te_labels[j]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(id_te_labels))]\n","Cell \u001b[0;32mIn[51], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[38;5;28mstr\u001b[39m([i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m id_te_labels[j]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(id_te_labels))]\n","Cell \u001b[0;32mIn[51], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[38;5;28mstr\u001b[39m([\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m id_te_labels[j]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(id_te_labels))]\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"code","source":"check_valid = pd.DataFrame(id_ds['validation']['raw_text'], columns=['clean_text'])\ncheck_valid['actual_label'] = id_te_labels\ncheck_valid['actual_aspects'] = [str([i.split(':')[0] for i in id_te_labels[j].split(',')]) for j in range(len(id_te_labels))]\ncheck_valid['actual_sentiments'] = valid_polarity\ncheck_valid['model_text_generated_label'] = id_te_pred_labels\ncheck_valid['predicted_aspects'] = [str([i.split(':')[0] for i in id_te_pred_labels[j].split(',')]) for j in range(len(id_te_pred_labels))]\ncheck_valid['predicted_sentiments'] = [str([i.split(':')[1] for i in id_te_pred_labels[j].split(',')]) for j in range(len(id_te_pred_labels))]\ncheck_valid['model_text_generate_probability']=id_te_pred_prob\ncheck_valid['dataset_type'] = ['valid']*check_valid.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:05:20.428101Z","iopub.execute_input":"2023-07-25T09:05:20.428479Z","iopub.status.idle":"2023-07-25T09:05:20.489533Z","shell.execute_reply.started":"2023-07-25T09:05:20.428448Z","shell.execute_reply":"2023-07-25T09:05:20.488048Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"check_test = pd.DataFrame(id_ds['test']['raw_text'], columns=['clean_text'])\ncheck_test['actual_label'] = id_test_labels\ncheck_test['actual_aspects'] = [str([i.split(':')[0] for i in id_test_labels[j].split(',')]) for j in range(len(id_test_labels))]\ncheck_test['actual_sentiments'] = [str([i.split(':')[1] for i in id_test_labels[j].split(',')]) for j in range(len(id_test_labels))]\ncheck_test['model_text_generated_label'] = id_test_pred_labels\ncheck_test['predicted_aspects'] = [str([i.split(':')[0] for i in id_test_pred_labels[j].split(',')]) for j in range(len(id_test_pred_labels))]\ncheck_test['predicted_sentiments'] = [str([i.split(':')[1] for i in id_test_pred_labels[j].split(',')]) for j in range(len(id_test_pred_labels))]\ncheck_test['model_text_generate_probability']=id_test_pred_prob\ncheck_test['dataset_type'] = ['test']*check_test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-07-25T08:32:36.721101Z","iopub.execute_input":"2023-07-25T08:32:36.721492Z","iopub.status.idle":"2023-07-25T08:32:36.764381Z","shell.execute_reply.started":"2023-07-25T08:32:36.721459Z","shell.execute_reply":"2023-07-25T08:32:36.761457Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"final = pd.concat([check.reset_index(drop=True),check_valid.reset_index(drop=True),check_test.reset_index(drop=True)])","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:05:45.161270Z","iopub.execute_input":"2023-07-25T09:05:45.162035Z","iopub.status.idle":"2023-07-25T09:05:45.186802Z","shell.execute_reply.started":"2023-07-25T09:05:45.161967Z","shell.execute_reply":"2023-07-25T09:05:45.185695Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"final.reset_index(drop=True, inplace=True)\nfinal.tail()","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:05:47.530202Z","iopub.execute_input":"2023-07-25T09:05:47.530597Z","iopub.status.idle":"2023-07-25T09:05:47.555938Z","shell.execute_reply.started":"2023-07-25T09:05:47.530558Z","shell.execute_reply":"2023-07-25T09:05:47.553346Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                                              clean_text  \\\n21190  Jaya Laxmi heart care seem okay l Madurai has ...   \n21191  Medi spring hospital and research center Rusta...   \n21192  Arthur as Irv at ham hospital ran an Nagar , M...   \n21193  the doctors at muck he ej a clinic full char G...   \n21194  this hospital has cutting edge equipment and a...   \n\n                                            actual_label  \\\n21190  madurai:Positive, jaya:Neutral, doctors:Positi...   \n21191  pharmacy:Positive, medicines:Neutral, gora:Neu...   \n21192  madurai:Positive, nagar:Neutral, hospital:Neut...   \n21193  gora:Positive, surgery:Positive, doctors:Posit...   \n21194  hospital:Positive, equipment:Positive, staff:P...   \n\n                                          actual_aspects  \\\n21190  ['madurai', ' jaya', ' doctors', ' heart', ' l...   \n21191  ['pharmacy', ' medicines', ' gora', ' hospital...   \n21192  ['madurai', ' nagar', ' hospital', ' arthur', ...   \n21193  ['gora', ' surgery', ' doctors', ' clinic', ' ...   \n21194  ['hospital', ' equipment', ' staff', ' trained...   \n\n                                       actual_sentiments  \\\n21190  ['Positive', 'Neutral', 'Positive', 'Neutral',...   \n21191  ['Positive', 'Neutral', 'Neutral', 'Neutral', ...   \n21192  ['Positive', 'Neutral', 'Neutral', 'Positive',...   \n21193  ['Positive', 'Positive', 'Positive', 'Neutral'...   \n21194  ['Positive', 'Positive', 'Positive', 'Positive...   \n\n                              model_text_generated_label  \\\n21190  madurai:Positive, jaya:Neutral, laxmi:Neutral,...   \n21191  pharmacy:Neutral, medicines:Neutral, gora:Neut...   \n21192  madurai:Positive, nagar:Neutral, hospital:Neut...   \n21193  gora:Positive, surgery:Positive, clinic:Neutra...   \n21194  hospital:Positive, equipment:Positive, staff:P...   \n\n                                       predicted_aspects  \\\n21190  ['madurai', ' jaya', ' laxmi', ' heart', ' doc...   \n21191  ['pharmacy', ' medicines', ' gora', ' hospital...   \n21192  ['madurai', ' nagar', ' hospital', ' doctors',...   \n21193  ['gora', ' surgery', ' clinic', ' doctors', ' ...   \n21194  ['hospital', ' equipment', ' staff', ' trained...   \n\n                                    predicted_sentiments  \\\n21190  ['Positive', 'Neutral', 'Neutral', 'Neutral', ...   \n21191  ['Neutral', 'Neutral', 'Neutral', 'Neutral', '...   \n21192  ['Positive', 'Neutral', 'Neutral', 'Positive',...   \n21193  ['Positive', 'Positive', 'Neutral', 'Positive'...   \n21194  ['Positive', 'Positive', 'Positive', 'Positive...   \n\n       model_text_generate_probability dataset_type  \n21190                         0.898708         test  \n21191                         0.665091         test  \n21192                         0.950015         test  \n21193                         0.933928         test  \n21194                         0.975610         test  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>actual_label</th>\n      <th>actual_aspects</th>\n      <th>actual_sentiments</th>\n      <th>model_text_generated_label</th>\n      <th>predicted_aspects</th>\n      <th>predicted_sentiments</th>\n      <th>model_text_generate_probability</th>\n      <th>dataset_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21190</th>\n      <td>Jaya Laxmi heart care seem okay l Madurai has ...</td>\n      <td>madurai:Positive, jaya:Neutral, doctors:Positi...</td>\n      <td>['madurai', ' jaya', ' doctors', ' heart', ' l...</td>\n      <td>['Positive', 'Neutral', 'Positive', 'Neutral',...</td>\n      <td>madurai:Positive, jaya:Neutral, laxmi:Neutral,...</td>\n      <td>['madurai', ' jaya', ' laxmi', ' heart', ' doc...</td>\n      <td>['Positive', 'Neutral', 'Neutral', 'Neutral', ...</td>\n      <td>0.898708</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>21191</th>\n      <td>Medi spring hospital and research center Rusta...</td>\n      <td>pharmacy:Positive, medicines:Neutral, gora:Neu...</td>\n      <td>['pharmacy', ' medicines', ' gora', ' hospital...</td>\n      <td>['Positive', 'Neutral', 'Neutral', 'Neutral', ...</td>\n      <td>pharmacy:Neutral, medicines:Neutral, gora:Neut...</td>\n      <td>['pharmacy', ' medicines', ' gora', ' hospital...</td>\n      <td>['Neutral', 'Neutral', 'Neutral', 'Neutral', '...</td>\n      <td>0.665091</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>21192</th>\n      <td>Arthur as Irv at ham hospital ran an Nagar , M...</td>\n      <td>madurai:Positive, nagar:Neutral, hospital:Neut...</td>\n      <td>['madurai', ' nagar', ' hospital', ' arthur', ...</td>\n      <td>['Positive', 'Neutral', 'Neutral', 'Positive',...</td>\n      <td>madurai:Positive, nagar:Neutral, hospital:Neut...</td>\n      <td>['madurai', ' nagar', ' hospital', ' doctors',...</td>\n      <td>['Positive', 'Neutral', 'Neutral', 'Positive',...</td>\n      <td>0.950015</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>21193</th>\n      <td>the doctors at muck he ej a clinic full char G...</td>\n      <td>gora:Positive, surgery:Positive, doctors:Posit...</td>\n      <td>['gora', ' surgery', ' doctors', ' clinic', ' ...</td>\n      <td>['Positive', 'Positive', 'Positive', 'Neutral'...</td>\n      <td>gora:Positive, surgery:Positive, clinic:Neutra...</td>\n      <td>['gora', ' surgery', ' clinic', ' doctors', ' ...</td>\n      <td>['Positive', 'Positive', 'Neutral', 'Positive'...</td>\n      <td>0.933928</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>21194</th>\n      <td>this hospital has cutting edge equipment and a...</td>\n      <td>hospital:Positive, equipment:Positive, staff:P...</td>\n      <td>['hospital', ' equipment', ' staff', ' trained...</td>\n      <td>['Positive', 'Positive', 'Positive', 'Positive...</td>\n      <td>hospital:Positive, equipment:Positive, staff:P...</td>\n      <td>['hospital', ' equipment', ' staff', ' trained...</td>\n      <td>['Positive', 'Positive', 'Positive', 'Positive...</td>\n      <td>0.975610</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"final.to_excel('key_result.xlsx',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:06:01.421096Z","iopub.execute_input":"2023-07-25T09:06:01.421508Z","iopub.status.idle":"2023-07-25T09:06:08.487130Z","shell.execute_reply.started":"2023-07-25T09:06:01.421476Z","shell.execute_reply":"2023-07-25T09:06:08.485921Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"final.to_csv('key_result.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:06:10.672703Z","iopub.execute_input":"2023-07-25T09:06:10.673114Z","iopub.status.idle":"2023-07-25T09:06:11.321708Z","shell.execute_reply.started":"2023-07-25T09:06:10.673080Z","shell.execute_reply":"2023-07-25T09:06:11.320385Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-07-25T07:32:55.385639Z","iopub.execute_input":"2023-07-25T07:32:55.386049Z","iopub.status.idle":"2023-07-25T07:32:55.392853Z","shell.execute_reply.started":"2023-07-25T07:32:55.386010Z","shell.execute_reply":"2023-07-25T07:32:55.391593Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_out_path)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_out_path)\n\nbos_instruction = \"\"\"Definition: The output will be the aspects (both implicit and explicit) and the aspects sentiment polarity. In cases where there are no aspects the output should be noaspectterm:none.\n    Positive example 1-\n    input: this hospital has a good team of doctors who will take care of all your needs brilliantly.\n    output: doctors:positive\n    Positive example 2- \n    input: Arthur as Irv at ham hospital ran an Nagar , Madurai has a doctor who engages you in a conversation and tries to take your mind off the pain and he has trained the staff to do so as well.\n    output: doctor:positive, staff:positive\n    Now complete the following example-\n    input: \"\"\"\ndelim_instruct = ''\neos_instruct = ' \\noutput:'\ntext = 'This hospital has doctors who gave me the best consultation even though it was not what other doctors would say. I was completely fine now because i followed thier advice.'\ntokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\noutput = model.generate(tokenized_text.input_ids,max_length=512)\nprint('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:07:40.102257Z","iopub.execute_input":"2023-07-25T09:07:40.102706Z","iopub.status.idle":"2023-07-25T09:07:45.574804Z","shell.execute_reply.started":"2023-07-25T09:07:40.102672Z","shell.execute_reply":"2023-07-25T09:07:45.573381Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Model output:  hospital:Positive, consultation:Positive, doctors:Positive, best:Positive, probably:Positive\n","output_type":"stream"}]},{"cell_type":"code","source":"text = 'Nobody caring here, i never suggest this hospital.'\ntokenized_text = tokenizer(bos_instruction + text + delim_instruct + eos_instruct, return_tensors=\"pt\")\noutput = model.generate(tokenized_text.input_ids,max_length=512)\nprint('Model output: ', tokenizer.decode(output[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-07-25T09:08:22.221680Z","iopub.execute_input":"2023-07-25T09:08:22.222106Z","iopub.status.idle":"2023-07-25T09:08:24.239072Z","shell.execute_reply.started":"2023-07-25T09:08:22.222070Z","shell.execute_reply":"2023-07-25T09:08:24.237630Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Model output:  hospital:Negative, suggest:Negative, care:Negative, hurt:Negative\n","output_type":"stream"}]}]}